# a note on naming conventions ####

# R objects and scripts = snake_case
# data files generated by R dataloaders = kebab-case
# JS code = camelCase

# it makes perfect sense to me...

# frequently used libraries ####

#library(knitr)
#library(kableExtra)

#library(readxl) 
#library(writexl)

library(jsonlite)
library(janitor)
#library(scales)
library(glue)

library(tidytext)

#library(tidyverse)
library(dplyr)
library(tidyr)
library(readr)
library(stringr)
library(purrr)

library(lubridate)
library(httr)
library(curl)

# viz/ggplot extras

#library(patchwork)

#library(ggthemes)
#library(ggalt)


# wikidata/sparql etc
#library(SPARQLchunks) # can't get chunks working! but it's fine for inline queries.

## functions from SPARQLchunks

#' Fetch data from a SPARQL endpoint and store the output in a dataframe
#' @param endpoint The SPARQL endpoint (a URL)
#' @param query The SPARQL query (character)
#' @param autoproxy Try to detect a proxy automatically (boolean). Useful on Windows machines behind corporate firewalls
#' @param auth Authentication Information (httr-authenticate-object)
#' @examples library(SPARQLchunks)
#' endpoint <- "https://lindas.admin.ch/query"
#' query <- "PREFIX schema: <http://schema.org/>
#'   SELECT * WHERE {
#'   ?sub a schema:DataCatalog .
#'   ?subtype a schema:DataType .
#' }"
#' result_df <- sparql2df(endpoint, query)
#' @export
sparql2df <- function(endpoint, query, autoproxy = FALSE, auth = NULL) {
  if (autoproxy) {
    proxy_config <- autoproxyconfig(endpoint)
  } else {
    proxy_config <- httr::use_proxy(url = NULL)
  }
  acceptype <- "text/csv"
  outcontent <- get_outcontent(endpoint, query, acceptype, proxy_config, auth)
  out <- textConnection(outcontent)
  df <- utils::read.csv(out)
  return(df)
}

#' Try to determine the proxy settings automatically
#' @param endpoint The SPARQL endpoint (URL)
autoproxyconfig <- function(endpoint) {
  message("Trying to determine proxy parameters")
  proxy_url <- tryCatch(
    {
      curl::ie_get_proxy_for_url(endpoint)
    },
    error = function(e) {
      message("Automatic proxy detection with curl::curl::ie_get_proxy_for_url() failed.")
      return(NULL)
    }
  )
  if (!is.null(proxy_url)) {
    message(paste("Using proxy:", proxy_url))
  } else {
    message(paste("No proxy found or needed to access the endpoint", endpoint))
  }
  return(httr::use_proxy(url = proxy_url))
}

#' Get the content from the endpoint
#' @param endpoint The SPARQL endpoint (URL)
#' @param query The SPARQL query (character)
#' @param acceptype 'text/csv' or 'text/xml' (character)
#' @param proxy_config Detected proxy configuration (list)
#' @param auth Authentication Information (httr-authenticate-object)
get_outcontent <- function(endpoint, query, acceptype, proxy_config, auth = NULL) {
  qm <- paste(endpoint, "?", "query", "=",
    gsub("\\+", "%2B", utils::URLencode(query, reserved = TRUE)), "",
    sep = ""
  )

  outcontent <- tryCatch(
    {
      out <- httr::GET(
        qm,
        proxy_config, auth,
        httr::timeout(60),
        httr::add_headers(c(Accept = acceptype))
      )
      httr::content(out, "text", encoding = "UTF-8")
    },
    error = function(e) {
      # @see https://github.com/r-lib/httr/issues/417 The download.file function in base R uses IE settings, including proxy password, when you use download
      # method wininet which is now the default on windows.
      if (.Platform$OS.type == "windows") {
        tempfile <- file.path(tempdir(), "temp.txt")
        utils::download.file(qm,
          method = "wininet",
          headers = c(Accept = acceptype),
          tempfile
        )
        temp <- paste(readLines(tempfile), collapse = "\n")
        unlink(tempfile)
        return(temp)
      }
    }
  )
  if (nchar(outcontent) < 1) {
    warning(paste0(
      "First query attempt result is empty. Trying without '",
      acceptype,
      "' header. The result is not guaranteed to be a list."
    ))
    outcontent <- tryCatch(
      {
        out <- httr::GET(
          qm,
          proxy_config, auth,
          httr::timeout(60)
        )
        if (out$status == 401) {
          warning("Authentication required. Provide valid authentication with the auth parameter")
        } else {
          httr::warn_for_status(out)
        }
        httr::content(out, "text", encoding = "UTF-8")
      },
      error = function(e) {
        if (.Platform$OS.type == "windows") {
          tempfile <- file.path(tempdir(), "temp.txt")
          utils::download.file(qm, method = "wininet", tempfile)
          temp <- paste(readLines(tempfile), collapse = "\n")
          unlink(tempfile)
          return(temp)
        }
      }
    )
    if (nchar(outcontent) < 1) {
      warning("The query result is still empty")
    }
  }
  return(outcontent)
}

## end of SPARQLchunks


# standard query using bn_prefixes and bn_endpoint. sparql= 'query string (excluding prefixes)'
bn_std_query <- function(sparql){
  c(paste(
    bn_prefixes,
    sparql
  )) |>
    sparql2df(endpoint=bn_endpoint) 
}


## endpoint ####

bn_endpoint <- "https://beyond-notability.wikibase.cloud/query/sparql"

## prefixes 

bn_prefixes <- 
"PREFIX bnwd: <https://beyond-notability.wikibase.cloud/entity/>
PREFIX bnwds: <https://beyond-notability.wikibase.cloud/entity/statement/>
PREFIX bnwdv: <https://beyond-notability.wikibase.cloud/value/>
PREFIX bnwdt: <https://beyond-notability.wikibase.cloud/prop/direct/>
PREFIX bnp: <https://beyond-notability.wikibase.cloud/prop/>
PREFIX bnps: <https://beyond-notability.wikibase.cloud/prop/statement/>
PREFIX bnpq: <https://beyond-notability.wikibase.cloud/prop/qualifier/> 
PREFIX bnpsv: <https://beyond-notability.wikibase.cloud/prop/statement/value/>
PREFIX bnpqv: <https://beyond-notability.wikibase.cloud/prop/qualifier/value/>
PREFIX bnwdref: <https://beyond-notability.wikibase.cloud/reference/>
PREFIX bnpr: <https://beyond-notability.wikibase.cloud/prop/reference/>
PREFIX bnprv: <https://beyond-notability.wikibase.cloud/prop/reference/value/>
"


# to make date and year given a single column named date, in wikibase format. won't work on edtf.
make_date_year <-function(data){
  data  |>
    mutate(date = if_else(str_detect(date, "^_:t"), NA, date))  |>
    mutate(date = parse_date_time(date, "ymdHMS"))  |>
    mutate(year = year(date))
}

# since i can never remember how to do this... make decades [0-9]
make_decade <- function(data, year) {
  data |>
    mutate(decade = {{year}} - ({{year}} %% 10)) |>
    relocate(decade, .after = {{year}})
}





# add date property labels inside a mutate
date_property_labels <- function(v) {
  case_when(
    {{v}}=="P1" ~ "point in time",
    {{v}}=="P27" ~ "start time",
    {{v}}=="P28" ~ "end time",
    {{v}}=="P53" ~ "earliest date",
    {{v}}=="P51" ~ "latest date"
  )
}




#mutate(across(c(a, b), ~str_extract(., "([^/]*$)") )) 
# previous: \\bQ\\d+$

# get an ID out of a wikibase item URL. v is often but not always person. could be eg item, place, woman, etc.
make_bn_item_id <- function(df, v) {
  df |>
    mutate(bn_id = str_extract({{v}}, "([^/]*$)")) |>
    relocate(bn_id)
}

# the same if it was a query for properties
make_bn_prop_id <- function(df, v) {
  df |>
    mutate(bn_prop_id = str_extract({{v}}, "([^/]*$)")) |>
    relocate(bn_prop_id)
}

# use across to extract IDs from URLs for 1 or more cols, no renaming or relocating
# across_cols can be any tidy-select kind of thing
# generally only use this on ID cols, but sometimes qualifiers can be mixed: what if there were a / somewhere in a non URI  ??? 
# could add http to the rgx? then you'd have to change to str_match.
make_bn_ids <- function(data, across_cols=NULL, ...) {
  data |>
    mutate(across({{across_cols}}, ~str_extract(., "([^/]*$)")))
}





## making union/values queries (usually for subquerying something already run)

# construct lists of IDs for union/values query; bn_id is default ID column but can name another.
# nb will still need to be enclosed in appropriate brackets in the sparql.
bn_make_union <- function(data, bn_id=bn_id){
  data |>
    mutate(bn_bnwd = paste0("bnwd:",{{bn_id}})) |> # for VALUES
    mutate(bn_bnwdt = paste0("bnwdt:",{{bn_id}})) |>
    mutate(bn_bnp = paste0("bnp:",{{bn_id}})) |>
    mutate(bn_bnps = paste0("bnps:", {{bn_id}})) |>
    mutate(wd = paste0("wd:", {{bn_id}})) |> # this one for a wikidata query
    # construct the contents of the UNION (add to sparql with data$thing or pull)
    # these need to be unique!
    summarise(bn_bnp_union = paste(unique(bn_bnp), collapse = " | "), 
              bn_bnps_union = paste(unique(bn_bnps), collapse = " | "), 
              bn_bnwd_values = paste(unique(bn_bnwd), collapse = " "),
              wd_values = paste(unique(wd), collapse = " "),
              bn_bnwdt_union = paste(unique(bn_bnwdt), collapse = " | ") ) 
}




## building query string for VALUES (or shorthand union) query, if it's not already saved as a thing.
## improved! RTFM and discovered .open and .close. options for glue
## now replaces the mutate(q=...) and pull stuff entirely.
## spql = the VALUES sparql query string from WQS; need to insert "glue_values" placeholder  
## default values = bn_bnwd_values for use with bn_make_union, but could be any list of Ps or Qs to go into a sparql.
## also a ptential template for more complex replacements... 
mutate_glue_sparql <- function(data, spql, values=bn_bnwd_values){
  data |>
    mutate(s = glue(
      spql,
      .open = "<<", .close = ">>"
    )) |>
    pull(s)
}

## example
# example_spql <- 
#   'select distinct ?item ?itemLabel ?location ?locationLabel ?wd
#     where {
#       values ?item { <<bn_bnwd_values>> }
#       ?item bnwdt:P2 ?location .
#       optional {?location bnwdt:P117 ?wd .}
#     SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en,en-gb". } 
#     }'
# bn_example_sparql <-
# bn_work_loc_query |>
#   filter(!is.na(location)) |>
#   bn_make_union(location) |>
#   mutate_glue_sparql(example_spql)
# bn_example_query <- bn_std_query(bn_example_sparql)





## dates of birth/death. - using this a lot now and it's not a heavy query, so it seems worth adding to the shared file.

bn_women_list_sparql <-
  'SELECT distinct ?person ?personLabel ?statements ?dob ?dod
WHERE {
   ?person bnwdt:P3 bnwd:Q3 ;
         wikibase:statements ?statements .
   FILTER NOT EXISTS {?person bnwdt:P4 bnwd:Q12 .}

      optional { ?person bnwdt:P15 ?dod .   }
      optional { ?person bnwdt:P26 ?dob .   }

    SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en,en-gb". } 
}'

# minimal processing to use as is or for dob/dod
# but there are dups because a few women have more than one dob/dod
bn_women_list <-
  bn_std_query(bn_women_list_sparql) |>
  make_bn_item_id(person) |>
  relocate(bn_id, personLabel) |>
  mutate(across(c(dob, dod), ~na_if(., ""))) |>
  arrange(parse_number(str_remove(bn_id, "Q")))

bn_women_list_deduped <-
bn_women_list |>
  mutate(across(c(dob, dod), ~parse_date_time(., "ymdHMS"), .names = "bn_{.col}")) |>
  mutate(across(c(bn_dob, bn_dod), year, .names = "{.col}_yr")) |>
  # only one row per person. earliest dob.
  group_by(bn_id) |>
  arrange(bn_dob, bn_dod, .by_group = TRUE) |>
  top_n(-1, row_number()) |>
  ungroup() 

bn_women_dob_dod <-
  bn_women_list_deduped |>
  select(-dob, -dod) |>
  filter(!is.na(bn_dob) | !is.na(bn_dod))




## all the properties in the wikibase with label 
bn_properties <-
  c("SELECT DISTINCT ?property ?propertyType ?propertyLabel 
      WHERE {
        ?property a wikibase:Property ;
              rdfs:label ?propertyLabel ;
              wikibase:propertyType ?propertyType .
  
      FILTER(LANG(?propertyLabel) = 'en') 
    }
    order by ?propertyLabel") |>
  sparql2df(endpoint=bn_endpoint) |>
  make_bn_prop_id(property) |>
  mutate(property_type = str_extract(propertyType, "[A-Za-z]+$")) |>
  relocate(property_type, .after = bn_prop_id) |>
  relocate(property, propertyType, .after = last_col())  |>
  arrange(parse_number(str_extract(bn_prop_id, "\\d+"))) 


## labels and display ####

# for abbreviating names of the three main societies in labels (use in a str_replace_all)
sal_rai_cas_abbr <-
  c("Society of Antiquaries of London"="SAL", "Royal Archaeological Institute"="RAI", "Congress of Archaeological Societies"="CAS")

##(make sure you do this after sal_rai_cas_abbr if you're using that)
organisations_abbr <-
  c("Archaeological" = "Arch", "Antiquarian" = "Antiq", "Society" = "Soc", "Association" = "Assoc")


